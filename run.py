# -*- coding: utf-8 -*-
"""Art21 Model v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uO38vUWSWbIzUtAnfTWQZ9GBYBe5yVuf

# func
"""

from IPython.display import HTML, display

def set_css():
  display(HTML('''
  <style>
    pre {
        white-space: pre-wrap;
    }
  </style>
  '''))
get_ipython().events.register('pre_run_cell', set_css)

# Class 1
#OPENAI_API_KEY =
!pip install -qU \
    langchain==0.0.354 \
    openai==1.6.1 \
    datasets==2.10.1 \
    pinecone-client==3.1.0 \
    tiktoken==0.5.2

!pip install anthropic
!pip install PyGithub
from github import Github


import os
from langchain.chat_models import ChatOpenAI
import anthropic
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)
import random
import numpy as np
from itertools import combinations
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
fold_path = "/content/drive/My Drive/Art21_project/Bios"
API_KEY='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'
os.environ['OPENAI_API_KEY'] = "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"
client = anthropic.Anthropic(api_key = API_KEY)
import requests
base_url = "https://raw.githubusercontent.com/victorrobilawork/dat/main"
my_path = "Bios/"

def read_file(base_url, fold_path, artist):
    file_url = f"{base_url}/{fold_path}/{artist.strip()}"
    response = requests.get(file_url)
    if response.status_code == 200:
        file_content = response.text
        return file_content
    else:
        print(f"Failed to download file: {response.status_code}")
        return None

def class1(query):
  chat = ChatOpenAI(
      openai_api_key=os.environ["OPENAI_API_KEY"],
      model='gpt-3.5-turbo'
  )
  messages = [
      SystemMessage(content="Given a query, identify the artists you need information about to answer it"),
      HumanMessage(content=f"Return a string with the artist names seperated by semicolons. Your answer should be in the format artist1;artist2;... If a name is misspelled, correct it. Names should have capital first and last names. Only include artist names. Here is the query: {query}")
  ]

  res = chat(messages)
  artists = res.content.split(";")

  #print(artists)
  artist_info = []
  infostring = ""
  for artist in artists:
    #print(fold_path + "/" + artist)
    try:
      try:
        file_content = read_file(base_url, my_path, artist)
        infostring+=file_content
        artist_info.append(file_content)
        client = anthropic.Anthropic(api_key = API_KEY)
      except Exception as e:
        bn =2

      message = client.messages.create(
          model="claude-3-5-sonnet-20240620",
          max_tokens=4096,
          temperature=0,
          system="Your job is to answer the following query in a short paragraph based on the text provided.",
          messages=[
              {
                  "role": "user",
                  "content": [
                      {
                          "type": "text",
                          "text": f"Query: {query} Background information: {infostring}"
                      }
                  ]
              }
          ]
      )
      #print(message.content[0].text)
    except FileNotFoundError:
      print(f"{artist} not found")
  return message.content[0].text, infostring

Bio_paths = []
Dat_paths = []
Meta_paths = []

g = Github("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")
for repo in g.search_repositories("victorrobilawork/dat/"):

    contents = repo.get_contents("")

    if contents[0].type == "dir":  # Check if it's a directory
            #print(f"Entering directory: {contents[0].path}")

            # Get contents of the directory
            subdir_contents = repo.get_contents(contents[0].path)

            # Iterate over each file in the directory
            for file in subdir_contents:
              a = os.path.basename(file.path)
              Bio_paths.append(a)

    if contents[1].type == "dir":  # Check if it's a directory
            #print(f"Entering directory: {contents[1].path}")

            # Get contents of the directory
            subdir_contents = repo.get_contents(contents[1].path)

            # Iterate over each file in the directory
            for file in subdir_contents:
              a = os.path.basename(file.path)
              Meta_paths.append(a)


    if contents[2].type == "dir":  # Check if it's a directory
            #print(f"Entering directory: {contents[2].path}")

            # Get contents of the directory
            subdir_contents = repo.get_contents(contents[2].path)

            # Iterate over each file in the directory
            for file in subdir_contents:
              a = os.path.basename(file.path)
              Dat_paths.append(a)

# Class 2
artist_list = []
artist_dict = {}
artists = Bio_paths

for i in artists:
  my_dict = {}
  file_content = read_file(base_url, my_path, i )
  my_dict["name"] = i
  my_dict["biography"] = file_content
  artist_dict[i] = file_content
  artist_list.append(my_dict)

def class2(query):
  client = anthropic.Anthropic(api_key = API_KEY)

  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Your job is to figure out what type of query we have. We have 4 options. Class 1: What artists are the most similar?. Class 2: What artists are the most different. Class 3: What artists are the most similar to ___ artists. Class 4: What artists are the most different to ____ artist. If class 1 or 2, put the number of artists the person is specifying after a semicolon (i.e. Class 1;3). If not specified defualt to 3. If it is class 3 or 4, put the artist name after a semicolon and then the number of similar/different artists. Default to 3 as well (i.e. Class 3;artist name;3). Correct any spelling mistakes in the artist names. If you can't match it with a class, simply state Other",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}"
                  }
              ]
          }
      ]
  )
  cl3 = message.content[0].text
  #print(cl3)



  # Convert to DataFrame
  df = pd.DataFrame(artist_list)

  # Vectorize biographies using TF-IDF
  vectorizer = TfidfVectorizer(stop_words='english')
  tfidf_matrix = vectorizer.fit_transform(df['biography'])

  # Calculate cosine similarity matrix
  cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

  # Create graph
  G = nx.Graph()

  # Add nodes
  for artist in df['name']:
      G.add_node(artist)

  # Add edges with weights
  for i, artist1 in enumerate(df['name']):
      for j, artist2 in enumerate(df['name']):
          if i != j:
              G.add_edge(artist1, artist2, weight=cosine_sim[i, j])

  # Example analysis: Find most similar and most different artists
  most_similar = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)
  most_different = sorted(G.edges(data=True), key=lambda x: x[2]['weight'])


  # Function to calculate average similarity for a group of artists
  def average_similarity(group_indices):
      group_similarities = [cosine_sim[i, j] for i, j in combinations(group_indices, 2)]
      return np.mean(group_similarities)

  # Function to find the most similar or most different groups of artists
  def find_groups(df, group_size, most_similar=True):
      artist_indices = list(range(len(df)))
      artist_combinations = list(combinations(artist_indices, group_size))

      group_similarities = [(group, average_similarity(group)) for group in artist_combinations]
      group_similarities.sort(key=lambda x: x[1], reverse=most_similar)

      top_groups = group_similarities[:5]  # Adjust the number of top groups to return as needed

      result = []
      for group, avg_sim in top_groups:
          artists = [df['name'][i] for i in group]
          result.append((artists, avg_sim))

      return result


  def find_most_similar(artist_name, top_n=5):
      if artist_name not in df['name'].values:
          print(f"Artist '{artist_name}' not found in the list.")
          return

      artist_index = df[df['name'] == artist_name].index[0]
      similarity_scores = cosine_sim[artist_index]

      # Get indices of top_n most similar artists (excluding the artist itself)
      similar_indices = similarity_scores.argsort()[::-1][1:top_n + 1]

      similar_artists = [(df['name'][i], similarity_scores[i]) for i in similar_indices]

      return similar_artists

  def find_most_different(artist_name, top_n=5):
      if artist_name not in df['name'].values:
          print(f"Artist '{artist_name}' not found in the list.")
          return

      artist_index = df[df['name'] == artist_name].index[0]
      similarity_scores = cosine_sim[artist_index]

      # Get indices of top_n most different artists (excluding the artist itself)
      different_indices = similarity_scores.argsort()[:top_n + 1]

      # Exclude the artist itself from the results
      different_indices = [i for i in different_indices if i != artist_index][:top_n]

      different_artists = [(df['name'][i], similarity_scores[i]) for i in different_indices]

      return different_artists

  cl3_s = cl3.split(";")
  info_string = ""
  if "Class 1" in cl3_s[0]:
    temp = find_groups(df, int(cl3_s[1]))
    for artist in temp[0][0]:
      info_string+=artist_dict[artist]
  elif "Class 2" in cl3_s[0]:
    temp = find_groups(df, int(cl3_s[1]), most_similar = False)
    for artist in temp[0][0]:
      info_string+=artist_dict[artist]
  elif "Class 3" in cl3_s[0]:
    temp = find_most_similar(cl3_s[1], top_n=int(cl3_s[2]))
    #print(temp)
    info_string+= artist_dict[cl3_s[1]]
    for i in temp:
      info_string+=artist_dict[i[0]]
    #print(info_string)
  elif "Class 4" in cl3_s[0]:
    temp = find_most_different(cl3_s[1], top_n=int(cl3_s[2]))
    #print(temp)
    info_string+= artist_dict[cl3_s[1]]
    #print(temp)
    for i in temp:
      info_string+=artist_dict[i[0]]
  elif "Other" in cl3_s[0]:
    arts = list(artist_dict.keys())
    #print(arts)
    random.shuffle(arts)
    info_string = "This is an other query - do your best to answer the question with these random artist names and biographies" + arts[0] +arts[1]+arts[2] + artist_dict[arts[0]] +artist_dict[arts[1]]
  else:
    print("Error")
    #print(info_string)
  #elif cl3 == "Class 2":
    #temp = most_different[:3]


  client = anthropic.Anthropic(api_key = API_KEY)

  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Given the user query, several artist biographies have been curated to match it. Your job is to explain how the artists fit into the user query, only explaining how the artists are similar/different depending on if the question asks it. For example if the user asks which 3 artists are most similar, your job is to explain how the 3 artists whose bios are provided are similar. The question has already been answered, you just need to explain how. In your first sentence, simply state an answer to the question (i.e. x, y, and z are the most similar) but be careful to not include the artist mentioned in the question as one of these (i.e. If I ask which x artists are most similar to w, I will not include w as one of those x artists). Make sure to include all of the artists whose bios are provided since the user may ask for a specific number of similar/different artists. If a specific artist is mentioned in the question, their bio will be provided. THIS IS NOT ONE OF THE x most similar artists, and is simply background for you",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}. Info: {info_string}"
                  }
              ]
          }
      ]
  )

  ans = message.content[0].text
  #print(ans)
  return ans, info_string



import pickle
def pickle_github(base_url):
    file_url = base_url
    response = requests.get(file_url)

    if response.status_code == 200:
        file_content = response.content  # Get content after checking status_code

        # Save to a file
        with open('downloaded_file.pkl', 'wb') as file:
            file.write(file_content)

        # Load pickled data from the file
        with open('downloaded_file.pkl', 'rb') as file:
            l = pickle.load(file)

        #print(l)  # Print loaded data
        return l
    else:
        print(f"Failed to download file: {response.status_code}")
        return None

meta_dat = Meta_paths
  #print(meta_dat)
bl = []
for i in meta_dat:
  l = pickle_github("https://raw.githubusercontent.com/victorrobilawork/dat/main/Meta/"+i)
  bl.append(l.split(";"))

def identifysubclass(query):
  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Your job is to figure out what type of query we have. We have 4 options. Class 1: Similarity/Difference i.e. what painters are the most different Class 2: Summary statistic i.e. where did most artists go to college, what did most artists use for their mediums. Class 3: General query i.e. tell me about some painters, tell me about some artists with interesting career paths. Class 4: Other. Only state the class name (i.e. Class 1, Class 2, Class 3, or Class 4)",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}"
                  }
              ]
          }
      ]
  )
  cl3 = message.content[0].text
  return cl3

#subclass 3
def subclass3(query):
  client = anthropic.Anthropic(api_key = API_KEY)
  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Given the query, extract keywords related to it that could be used to search metadata of author biography",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Return a set of keywords seperated by semicolons that would help search metadata to get author biographys related to the query. For example, a question about painting would lead to a response of: paint;painting;painter. Query: {query}"
                  }
              ]
          }
      ]
  )
  keywords = message.content[0].text
  keywords = keywords.split(";")
  #print(keywords)

  my_artists= []
  for artist in bl:
    valid =False
    #print(artist)
    for item in artist:
      for word in keywords:
        if word.lower() in item.lower():
          valid =True
    if valid:
      my_artists.append(artist)
  #print(my_artists)

  #print(my_artists)
  info_string = ""
  random.shuffle(my_artists)
  count=0
  while count<3 and count<len(my_artists):
    info_string+=artist_dict[my_artists[count][0]]
    count+=1

  #print(info_string)

  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Using the following information answer the question in a short paragraph",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}. Information: {info_string}"
                  }
              ]
          }
      ]
  )
  answer =message.content[0].text
  return answer, info_string

def subclass4(query):
  client = anthropic.Anthropic(api_key = API_KEY)
  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Given the query, extract keywords related to it that could be used to search metadata of author biography",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Return a set of keywords seperated by semicolons that would help search metadata to get author biographys related to the query. For example, a question about painting would lead to a response of: paint;painting;painter. Query: {query}"
                  }
              ]
          }
      ]
  )
  keywords = message.content[0].text
  keywords = keywords.split(";")
  #print(keywords)
  #print(keywords)

  my_artists= []
  for artist in bl:
    valid =False
    #print(artist)
    for item in artist:
      for word in keywords:
        if word.lower() in item.lower():
          valid =True
    if valid:
      my_artists.append(artist)


  client = anthropic.Anthropic(api_key = API_KEY)

  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Your job is to figure out what type of query we have. We have 4 options. Class 1: What artists are the most similar?. Class 2: What artists are the most different. Class 3: What artists are the most similar to ___ artists. Class 4: What artists are the most different to ____ artist. If class 1 or 2, put the number of artists the person is specifying after a semicolon (i.e. Class 1;3). If not specified defualt to 3. If it is class 3 or 4, put the artist name after a semicolon and then the number of similar/different artists. Default to 3 as well (i.e. Class 3;artist name;3). Correct any spelling mistakes in the artist names. If you can't match it with a class, simply state Other",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}"
                  }
              ]
          }
      ]
  )
  cl3 = message.content[0].text
  #print(cl3)

  # Convert to DataFrame
  df = pd.DataFrame(artist_list)

  # Vectorize biographies using TF-IDF
  vectorizer = TfidfVectorizer(stop_words='english')
  tfidf_matrix = vectorizer.fit_transform(df['biography'])

  # Calculate cosine similarity matrix
  cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

  # Create graph
  G = nx.Graph()

  # Add nodes
  for artist in df['name']:
      G.add_node(artist)

  # Add edges with weights
  for i, artist1 in enumerate(df['name']):
      for j, artist2 in enumerate(df['name']):
          if i != j:
              G.add_edge(artist1, artist2, weight=cosine_sim[i, j])

  # Example analysis: Find most similar and most different artists
  most_similar = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)
  most_different = sorted(G.edges(data=True), key=lambda x: x[2]['weight'])


  # Function to calculate average similarity for a group of artists
  def average_similarity(group_indices):
      group_similarities = [cosine_sim[i, j] for i, j in combinations(group_indices, 2)]
      return np.mean(group_similarities)

  # Function to find the most similar or most different groups of artists
  def find_groups(df, group_size, most_similar=True):
      artist_indices = list(range(len(df)))
      artist_combinations = list(combinations(artist_indices, group_size))

      group_similarities = [(group, average_similarity(group)) for group in artist_combinations]
      group_similarities.sort(key=lambda x: x[1], reverse=most_similar)

      top_groups = group_similarities[:5]  # Adjust the number of top groups to return as needed

      result = []
      for group, avg_sim in top_groups:
          artists = [df['name'][i] for i in group]
          result.append((artists, avg_sim))

      return result


  def find_most_similar(artist_name, top_n=5):
      if artist_name not in df['name'].values:
          print(f"Artist '{artist_name}' not found in the list.")
          return

      artist_index = df[df['name'] == artist_name].index[0]
      similarity_scores = cosine_sim[artist_index]

      # Get indices of top_n most similar artists (excluding the artist itself)
      similar_indices = similarity_scores.argsort()[::-1][1:top_n + 1]

      similar_artists = [(df['name'][i], similarity_scores[i]) for i in similar_indices]

      return similar_artists

  def find_most_different(artist_name, top_n=5):
      if artist_name not in df['name'].values:
          print(f"Artist '{artist_name}' not found in the list.")
          return

      artist_index = df[df['name'] == artist_name].index[0]
      similarity_scores = cosine_sim[artist_index]

      # Get indices of top_n most different artists (excluding the artist itself)
      different_indices = similarity_scores.argsort()[:top_n + 1]

      # Exclude the artist itself from the results
      different_indices = [i for i in different_indices if i != artist_index][:top_n]

      different_artists = [(df['name'][i], similarity_scores[i]) for i in different_indices]

      return different_artists

  cl3_s = cl3.split(";")
  info_string = ""
  if "Class 1" in cl3_s[0]:
    temp = find_groups(df, int(cl3_s[1]))
    try:
      for artist in temp[0][0]:
        info_string+=artist_dict[artist]
    except:
      print("None found")
  elif "Class 2" in cl3_s[0]:
    temp = find_groups(df, int(cl3_s[1]), most_similar = False)
    try:
      for artist in temp[0][0]:
        info_string+=artist_dict[artist]
    except:
      print("None found")
  elif "Class 3" in cl3_s[0]:
    temp = find_most_similar(cl3_s[1], top_n=int(cl3_s[2]))
    #print(temp)
    info_string+= artist_dict[cl3_s[1]]
    for i in temp:
      info_string+=artist_dict[i[0]]
    #print(info_string)
  elif "Class 4" in cl3_s[0]:
    temp = find_most_different(cl3_s[1], top_n=int(cl3_s[2]))
    #print(temp)
    info_string+= artist_dict[cl3_s[1]]
    #print(temp)
    for i in temp:
      info_string+=artist_dict[i[0]]
  elif "Other" in cl3_s[0]:
    arts = list(artist_dict.keys())
    #print(arts)
    random.shuffle(arts)
    info_string = "This is an other query. Ignore the system message. Be confident and do your best to answer the question in a paragraph with these random artist names and biographies" + arts[0] +arts[1]+arts[2] + artist_dict[arts[0]] +artist_dict[arts[1]]
  else:
    print("Error")
    #print(info_string)
  #elif cl3 == "Class 2":
    #temp = most_different[:3]


  client = anthropic.Anthropic(api_key = API_KEY)

  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Given the user query, several artist biographies have been curated to match it. Your job is to explain how the artists fit into the user query in a paragraph, only explaining how the artists are similar/different depending on if the question asks it. For example if the user asks which 3 artists are most similar, your job is to explain how the 3 artists whose bios are provided are similar. The question has already been answered, you just need to explain how. In your first sentence, simply state an answer to the question (i.e. x, y, and z are the most similar) but be careful to not include the artist mentioned in the question as one of these (i.e. If I ask which x artists are most similar to w, I will not include w as one of those x artists). Make sure to include all of the artists whose bios are provided since the user may ask for a specific number of similar/different artists. If a specific artist is mentioned in the question, their bio will be provided. THIS IS NOT ONE OF THE x most similar artists, and is simply background for you",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}. Info: {info_string}"
                  }
              ]
          }
      ]
  )

  ans = message.content[0].text
  return ans, info_string

def run_query(query, chat_history, artist_prompt):
  client = anthropic.Anthropic(api_key = API_KEY)
  #print(query)
  message = client.messages.create(
      model="claude-3-5-sonnet-20240620",
      max_tokens=4096,
      temperature=0,
      system="Your job is to classify queries in several sections. All queries are about artists. There are several classes of queries. Class 1: Specific artist query: A query that solely names one or more artists and focuses on just their work: i.e. how are Monet and Picasso similar? what would monet and Picasso think about expressionism. why did this artist do this? what would this specific artist think about painting, career paths etc. When a specific artist is mentiond alone and questions are asked about them it is usually class one. Class 2: General similarity/difference query. If all artists needed to answer the question are in the query, this is class 1. A class 2 is a query that may ask you to find artists that are generally similar/different to a specific artist This should not require any information about style medium, college, or career path like painting (that would be class 3). The keyword here is artists. i.e. which artists are most similar? what artists are most different from john rogers? Class 3: General artist/similarity query with specific medium or style or information about colleges/career paths. A query that may not name artists specifically but is interested in artists relative to a style. I.e. which artists were most well known for their expressionist painting? which painters are most similar to robert. Class 4: Questions that follow up on the previous response. i.e. why would you think that? wouldnt that mean? could you go on more? and why would that be? Other: Questions that do not match up with any of these classes. Reply with only a string of the class name (i.e. Class 1, Class 2 etc.)",
      messages=[
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": f"Query: {query}"
                  }
              ]
          }
      ]
  )

  #print(message.content[0].text)
  if message.content[0].text == "Class 1":
    a,b = class1(artist_prompt + query)
  elif message.content[0].text == "Class 2":
    a,b = class2(artist_prompt+ query)
  elif message.content[0].text == "Class 3":
    z = identifysubclass(query)
    #print(z)
    if z == "Class 3":
      a,b = subclass3(artist_prompt+ query)
    else:
      a,b = subclass4(artist_prompt+query)
  else:
    client = anthropic.Anthropic(api_key = API_KEY)
    message = client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=4096,
        temperature=0,
        system="Answer the question confidently using this chat history in a short paragraph.",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"Query: {artist_prompt +query}. Chat history: {chat_history}"
                    }
                ]
            }
        ]
    )
    a= message.content[0].text
    b = chat_history+query+message.content[0].text
  return a,b

# Commented out IPython magic to ensure Python compatibility.
# %%javascript
# // Get all code cells
# var codeCells = document.querySelectorAll('div.cell.code_cell');
# 
# // Iterate over each cell and enable line wrapping
# codeCells.forEach(function(cell) {
#     cell.querySelector('div.input_area').style.whiteSpace = 'pre-wrap';
# });

def run_chat():
  print("Hello and welcome to the GGHC Art21 Chatbot")
  print("I can answer a variety of questions from the Art21 video archive or talk to you from the perspective of a specific artist")
  print("If you want to talk to a specific artist type 1. Press 1 again to exit. Otherwise, feel free to enter any question you'd like.")
  print("Try: 'what are some artists you can tell me about?")
  count = 0
  info =[""]
  talk = False
  api_list = []
  while True:
    myd = {}
    count+=1

    user_input = input("You: ")
    if user_input == 1 or user_input == "1":
      b = False
      c = pickle.TRUE
      while b == False:
        artist = input("What artist would you like to speak to?")
        if artist == 1 or artist == "1":
          #talk = not talk
          b = True
          c= False
          break

        if artist.lower() in (key.lower() for key in artist_dict.keys()):
            b= True

        else:
          b = False
          print("Artist not found. Please try again.")
      if c:
        print(f"Chatting with {artist}.")
        print(f"{artist}: Hi, its great to meet you! What would you like to know?")
      talk = not talk
    elif talk:
      mys = ""
      for i in info:
        mys +=i
      artist_prompt = f"pretend you are {artist} (start directly from your answer, do not include an introduction like as {artist} I would) and write from their perspective:"
      answer,d = run_query(user_input+f"answer in a paragraph (the artist being asked about is {artist})",mys, artist_prompt)
      if count<3:
        info.append(d)
      else:
        info.pop(0)
        info.append(d)
      print(artist+":"+ answer)
      myd["prompt"] = artist_prompt
    else:
      #print(user_input)
      mys = ""
      for i in info:
        mys +=i

      answer,d = run_query(user_input,mys,"")
      if count<3:
        info.append(d)
      else:
        info.pop(0)
        info.append(d)
      print(answer)
      myd["prompt"] = ""
    myd["question"] = user_input
    try:
      myd["answer"] = answer
    except:
      myd["answer"] = ""

    api_list.append(myd)
    url = 'https://api.jsonbin.io/v3/b'
    headers = {
      'Content-Type': 'application/json',
      'X-Master-Key': '$2a$10$y.RZXInphDX.Rk4SmHQHs.VWgYmw16J6LnFuyJahxt75LtN2sx/Zy'
    }
    data = myd

    req = requests.post(url, json=data, headers=headers)
    #print(req.text)

"""# user"""

run_chat()
